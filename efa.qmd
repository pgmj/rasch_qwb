---
title: "Questionnaire on Well-Being (QWB)"
subtitle: "Reproducing EFA"
title-block-banner: "#009ca6"
title-block-banner-color: "#FFFFFF"
author: 
  name: Magnus Johansson
  affiliation: RISE Research Institutes of Sweden
  affiliation-url: https://www.ri.se/en/kbm
  orcid: 0000-0003-1669-592X
date: last-modified
date-format: iso
always_allow_html: true
format: 
  html:
    toc: true
    toc-depth: 3
    toc-title: "Table of contents"
    embed-resources: true
    standalone: true
    page-layout: full
    mainfont: 'Lato'
    monofont: 'Roboto Mono'
    code-overflow: wrap
    code-fold: true
    code-tools: true
    code-link: true
    number-sections: true
    fig-dpi: 96
    layout-align: left
    linestretch: 1.6
    theme:
      - materia
      - custom.scss
    css: styles.css
    license: CC BY
  pdf:
    papersize: a4
    documentclass: report 
execute:
  echo: true
  warning: false
  message: false
  cache: false
editor_options: 
  markdown: 
    wrap: 72
  chunk_output_type: console
---

```{r}
#| label: setup

library(readxl)
library(tidyverse)
library(RISEkbmRasch) # devtools::install_github("pgmj/RISEkbmRasch")

### some commands exist in multiple packages, here we define preferred ones that are frequently used
select <- dplyr::select
count <- dplyr::count
recode <- car::recode
rename <- dplyr::rename
```
Questionnaire on Well-Being
(QWB), 18 items, each item is scored on a scale of 0
to 4 [@hlynsson_evaluating_2024]. Data from the same paper. We'll use the data from the first study that was used in the EFA in the paper.

```{r}
### import data - this is just sample code, the files do not exist
d1 <- read_excel("data/study_one.xlsx") # replace with your datafile as needed

### Load item information
# make sure that variable names in df match with itemlabels$itemnr
itemlabels <- data.frame(
  stringsAsFactors = FALSE,
  itemnr = paste0("swb", 1:18),
  item = c(
    "... felt calm and relaxed?",
    "... had a good appetite and enjoyed eating?",
    "... have been able to take initiatives and get started with what you wanted to do?",
    "... felt optimistic and viewed things on the bright side?",
    "... felt active and filled with energy?",
    "... felt a strong zest for life?",
    "... been able to object and to assert yourself when this is needed?",
    "... felt satisfied with your life in its present situation?",
    "... felt that your life is meaningful?",
    "... slept well and got the right amount of sleep?",
    "... have been able to be focused and concentrated on today’s tasks?",
    "... felt interested in various activities and in people around you?",
    "... felt happy and harmonious?",
    "... felt satisfied with yourself?",
    "... been able to make decisions and carry them out?",
    "... been able to stay in the here and now and to let go of thoughts about problems?",
    "... had the power to recover one’s strength if something has been stressful or difficult?",
    "... felt that you are well and healthy?"
  )
)
#write_csv(itemlabels,"data/itemlabels_swb.csv")
```

```{r}
# swb items extract
df <- d1 %>% 
  select(starts_with("qwb")) %>% 
  select(contains("screening")) %>% 
  select(!contains("sum")) %>% 
  set_names(itemlabels$itemnr)
```

```{r}
RImissing(df)
RImissingP(df,n = 1000)
```

All participants that have missing data are completely missing (no missing data on item level), except one respondent with 33.3% missing. We will remove all those with any missing responses from our data.

```{r}
nrow(df)
df %>% 
  na.omit() %>% 
  nrow()

df <- na.omit(df)
```

We end up with 494 respondents, which is identical to the complete responders in the paper.

## All items in the analysis
```{r}
RIlistitems(df)
```

## Descriptives of raw data

Response distribution for all items are summarized below.

```{r}
#| tbl-cap: "Total number of responses for all items"
RIallresp(df)
```

### Descriptives - item level

```{r}
#| column: margin
RIlistItemsMargin(df, fontsize = 12)
```

::: panel-tabset
#### Tile plot
```{r}
RItileplot(df)
```
#### Stacked bars
```{r}
RIbarstack(df)
```
#### Barplots
```{r}
#| layout-ncol: 3
RIbarplot(df)
```
#### Expected value curves
```{r}
#| layout-ncol: 3
library(TAM)
tam1 <- tam(as.matrix(df), irtmodel = "PCM", verbose = FALSE) # run TAM Rasch Partial Credit Model on our data, which uses Marginal Maximum Likelihood estimation
plot(tam1) # create ICC plots
```
:::

Some cells have few (4-6) responses. No items need reverse scoring.


## Exploratory factor analysis

Let's look at the data using EFA. A lot of the code for this analysis was borrowed from <https://solomonkurz.netlify.app/blog/2021-05-11-yes-you-can-fit-an-exploratory-factor-analysis-with-lavaan/>

Since the paper used varimax rotation and WLSMV estimator, we will do the same.

```{r}
library(lavaan)
f1 <- 'efa("efa")*f1 =~ swb1 + swb2 + swb3 + swb4 + swb5 + swb6 + swb7 + swb8 +
                    swb9 + swb10 + swb11 + swb12 + swb13 + swb14 + swb15 + 
                    swb16 + swb17 + swb18'

# 2-factor model
f2 <- 'efa("efa")*f1 + 
       efa("efa")*f2 =~ swb1 + swb2 + swb3 + swb4 + swb5 + swb6 + swb7 + swb8 +
                    swb9 + swb10 + swb11 + swb12 + swb13 + swb14 + swb15 + 
                    swb16 + swb17 + swb18'

# 3-factor
f3 <- '
efa("efa")*f1 +
efa("efa")*f2 +
efa("efa")*f3 =~ swb1 + swb2 + swb3 + swb4 + swb5 + swb6 + swb7 + swb8 +
                    swb9 + swb10 + swb11 + swb12 + swb13 + swb14 + swb15 + 
                    swb16 + swb17 + swb18'

# 4-factor
f4 <- '
efa("efa")*f1 +
efa("efa")*f2 +
efa("efa")*f3 +
efa("efa")*f4 =~ swb1 + swb2 + swb3 + swb4 + swb5 + swb6 + swb7 + swb8 +
                    swb9 + swb10 + swb11 + swb12 + swb13 + swb14 + swb15 + 
                    swb16 + swb17 + swb18'

# 5-factor
f5 <- '
efa("efa")*f1 +
efa("efa")*f2 +
efa("efa")*f3 +
efa("efa")*f4 + 
efa("efa")*f5 =~ swb1 + swb2 + swb3 + swb4 + swb5 + swb6 + swb7 + swb8 +
                    swb9 + swb10 + swb11 + swb12 + swb13 + swb14 + swb15 + 
                    swb16 + swb17 + swb18'

efa_f1 <- 
  cfa(model = f1,
      data = df,
      rotation = "varimax",
      estimator = "WLSMV",
      ordered = TRUE)
efa_f2 <- 
  cfa(model = f2,
      data = df,
      rotation = "varimax",
      estimator = "WLSMV",
      ordered = TRUE)
efa_f3 <- 
  cfa(model = f3,
      data = df,
      rotation = "varimax",
      estimator = "WLSMV",
      ordered = TRUE)
efa_f4 <- 
  cfa(model = f4,
      data = df,
      rotation = "varimax",
      estimator = "WLSMV",
      ordered = TRUE)
efa_f5 <- 
  cfa(model = f5,
      data = df,
      rotation = "varimax",
      estimator = "WLSMV",
      ordered = TRUE)

```

### Scaled fit metrics

For WLSMV, [the .scaled metrics should be reported](https://rpubs.com/dmcneish/1025400).

```{r}
fit_metrics_scaled <- c("chisq.scaled", "df", "pvalue.scaled", 
                        "cfi.scaled", "tli.scaled", "rmsea.scaled", 
                        "rmsea.ci.lower.scaled","rmsea.ci.upper.scaled",
                        "srmr")


rbind(
  fitmeasures(efa_f1, fit_metrics_scaled),
  fitmeasures(efa_f2, fit_metrics_scaled),
  fitmeasures(efa_f3, fit_metrics_scaled),
  fitmeasures(efa_f4, fit_metrics_scaled),
  fitmeasures(efa_f5, fit_metrics_scaled)
  ) %>% 
  as.data.frame() %>% 
  mutate(across(where(is.numeric),~ round(.x, 3))) %>%
  rename(Chi2.scaled = chisq.scaled,
         p.scaled = pvalue.scaled,
         CFI.scaled = cfi.scaled,
         TLI.scaled = tli.scaled,
         RMSEA.scaled = rmsea.scaled,
         CI_low.scaled = rmsea.ci.lower.scaled,
         CI_high.scaled = rmsea.ci.upper.scaled,
         SRMR = srmr) %>% 
  add_column(Model = paste0(1:5,"-factor"), .before = "Chi2.scaled") %>% 
  knitr::kable()
```

Since these are ordinal data used with WLSMV, we cannot apply rule of thumb cutoff values such as Hu & Bentler [-@hu_cutoff_1999], since those are based on continuous data and maximum likelihood estimation. But we can see what happens with the different metrics in the different models and how they compare.

### Factor loadings 1-factor

```{r}
standardizedsolution(efa_f1) %>% 
  filter(op == "=~") %>% 
  mutate(item  = str_remove(rhs, "swb") %>% as.double(),
         factor = str_remove(lhs, "f"))
```

All loadings (`est.std` in the table above) are above 0.4 in the one-factor model. Let's review the modification indices, filtered to only include those with mi/chi2 values above 15.

### Modification indices 1-factor

```{r}
modificationIndices(efa_f1,
                    standardized = T) %>% 
  as.data.frame(row.names = NULL) %>% 
  filter(mi > 15) %>% 
  arrange(desc(mi)) %>% 
  mutate(across(where(is.numeric),~ round(.x, 3))) %>%
  knitr::kable()
```

Here we can see several large residual correlations. These are the top 8:

- items 4 and 5
- 7 and 8
- 1 and 2
- 15 and 17
- 5 and 12
- 11 and 17
- 1 and 16
- 5 and 6

There seems to be some clustering going on here, which indicates multiple dimensions.

Let's look at the 3 factor model as a comparison, and review how the items listed above fit in the 3 factors.

### Plot 3-factor model

In the paper, the lowest standardized factor loading considered acceptable is 0.3, so we will use that here as well.

```{r}
#| fig-height: 8
standardizedsolution(efa_f3) %>% 
  filter(op == "=~") %>% 
  mutate(item  = str_remove(rhs, "swb") %>% as.double(),
         factor = str_remove(lhs, "f")) %>% 
  # plot
  ggplot(aes(x = est.std, xmin = ci.lower, xmax = ci.upper, y = item)) +
  annotate(geom = "rect",
           xmin = -1, xmax = 1,
           ymin = -Inf, ymax = Inf,
           fill = "grey90") +
  annotate(geom = "rect",
           xmin = -0.7, xmax = 0.7,
           ymin = -Inf, ymax = Inf,
           fill = "grey93") +
  annotate(geom = "rect",
           xmin = -0.3, xmax = 0.3,
           ymin = -Inf, ymax = Inf,
           fill = "grey96") +
  geom_vline(xintercept = 0, color = "white") +
  geom_pointrange(aes(alpha = abs(est.std) < 0.3),
                  fatten = 10) +
  geom_text(aes(label = item, color = abs(est.std) < 0.3),
            size = 4) +
  scale_color_manual(values = c("white", "transparent")) +
  scale_alpha_manual(values = c(1, 1/3)) +
  scale_x_continuous(expression(lambda[standardized]), 
                     expand = c(0, 0), limits = c(-1, 1),
                     breaks = c(-1, -0.7, -0.3, 0, 0.3, 0.7, 1),
                     labels = c("-1", "-.7", "-.3", "0", ".3", ".7", "1")) +
  scale_y_continuous(breaks = 1:18, sec.axis = sec_axis(~ . * 1, breaks = 1:18)) +
  ggtitle("Factor loadings for the 3-factor model") +
  theme(legend.position = "none") +
  facet_wrap(~ factor, labeller = label_both) 
```

Several crossloadings are apparent when using the low cutoff of 0.3. Let's raise the bar to 0.4 and perhaps achieve more clarity.

```{r}
#| fig-height: 8
standardizedsolution(efa_f3) %>% 
  filter(op == "=~") %>% 
  mutate(item  = str_remove(rhs, "swb") %>% as.double(),
         factor = str_remove(lhs, "f")) %>% 
  # plot
  ggplot(aes(x = est.std, xmin = ci.lower, xmax = ci.upper, y = item)) +
  annotate(geom = "rect",
           xmin = -1, xmax = 1,
           ymin = -Inf, ymax = Inf,
           fill = "grey90") +
  annotate(geom = "rect",
           xmin = -0.7, xmax = 0.7,
           ymin = -Inf, ymax = Inf,
           fill = "grey93") +
  annotate(geom = "rect",
           xmin = -0.4, xmax = 0.4,
           ymin = -Inf, ymax = Inf,
           fill = "grey96") +
  geom_vline(xintercept = 0, color = "white") +
  geom_pointrange(aes(alpha = abs(est.std) < 0.4),
                  fatten = 10) +
  geom_text(aes(label = item, color = abs(est.std) < 0.4),
            size = 4) +
  scale_color_manual(values = c("white", "transparent")) +
  scale_alpha_manual(values = c(1, 1/3)) +
  scale_x_continuous(expression(lambda[standardized]), 
                     expand = c(0, 0), limits = c(-1, 1),
                     breaks = c(-1, -0.7, -0.4, 0, 0.4, 0.7, 1),
                     labels = c("-1", "-.7", "-.4", "0", ".4", ".7", "1")) +
  scale_y_continuous(breaks = 1:18, sec.axis = sec_axis(~ . * 1, breaks = 1:18)) +
  ggtitle("Factor loadings for the 3-factor model") +
  theme(legend.position = "none") +
  facet_wrap(~ factor, labeller = label_both) 
```

These are the residual correlations from the 1-factor model sorted into factors in the model above:

factor 1:

- 4 and 5
- 5 and 6
- 5 and 12

factor 2:

- 1 and 2
- 1 and 16

factor 3:

- 7 and 8
- 15 and 17
- 11 and 17

Item pairs with residual correlations indicates that either the items make up a separate dimension/cluster in data, and/or they are too similar in content and only one of the two items can be included in the scale.

For unidimensionality to hold, there cannot be local dependence between items - items should only be related through the latent variable. Residuals are the variance in an item that is not explained by the latent variable, and thus the pattern of residuals is important to assess local dependence. Residual correlations are such a pattern.

### Modification indices 3-factor

```{r}
modificationIndices(efa_f3,
                    standardized = T) %>% 
  as.data.frame(row.names = NULL) %>% 
  filter(mi > 5) %>% 
  arrange(desc(mi)) %>% 
  mutate(across(where(is.numeric),~ round(.x, 3))) %>%
  knitr::kable()
```

A lot of residual correlations, particularly in the 3rd factor, which also has the most items.

## Summary comments

These 18 items are clearly not unidimensional and should not be sum scored. Further work is needed to assess dimensionality to arrive at a set of items that fulfill unidimensionality requirements.

## Software used
```{r}
sessionInfo()
```

## References
